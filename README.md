# Introduction to Machine Learning

## Overview

Welcome to this little lecture on machine learning (ML). 

ML can be viewed as a collection of statistical algorithms used to

1. predict a target variable based on features (supervised ML) or to
2. investigate data structure (unsupervised ML).

Our focus is on *supervised algorithms*. These are often split by the data type of the response variable. If the latter is numeric (house prices, blood pressure, insurance claim counts/amounts), we talk of *regression*. If the response variable is categorical (house type, medical diagnosis, sentiment of an email), we are in the field of classification. The binary case can be tackled by both.

## Organization

The lecture is split into four parts, each of which is accompanied with an R and Python notebook with examples. You will find them in the corresponding subfolders.

1. Regression and Classification Revisited 
2. Model Selection
    - Performance metrics and loss functions
    - Simple validation, cross-validation
    - Grid search
3. Trees
    - Decision trees
    - Random forests
    - Gradient boosting
4. Neural Nets

## References

1. James, G., Witten, D., Hastie, T., Tibshirani, R. (2013). *An Introduction to Statistical Learning - with Applications in R*. New York, USA: Springer New York Inc.

2. Hastie, T., Tibshirani, R., Friedman, J. (2001). *The Elements of Statistical Learning*. New York, USA: Springer New York Inc.

3. Wickham, H., Grolemund, G. (2017). *R for Data Science: Import, Tidy, Transform, Visualize, and Model Data*. O'Reilly Media. 

4. VanderPlas, J. (2016). *Python data science handbook : essential tools for working with data*. Sebastopol, CA: O'Reilly Media, Inc.

5. Chollet, F. (2017). *Deep Learning with Python*. Manning.

6. Chollet, F., Allaire, J. J. (2018). *Deep Learning with R*. Manning.



